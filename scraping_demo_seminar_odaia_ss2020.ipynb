{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scraping_demo_seminar_odaia_ss2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.6.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xvariable/RoogleVision/blob/master/scraping_demo_seminar_odaia_ss2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L7KD3mNCnVV_"
      },
      "source": [
        "# Web Scraping in R\n",
        "\n",
        "Dr. Julia Niemann-Lenz\n",
        "\n",
        "Hochschule für Musik, Theater & Medien Hannover, Institut für Journalistik & Kommunikationswissenschaft\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MWKJCazyDu8_"
      },
      "source": [
        "# Worum geht es beim Web Scraping?\n",
        "Nicht alle Webseiten haben eine API, im Prinzip ist dennoch jeder Inhalt, den man im Internet ansehen kann, auch downloadbar. Das systematische und maschinelle Herunterladen wird als Web Scraping (engl. „schlürfen“) bezeichnet.\n",
        "\n",
        "WWW-Content ist in erster Linie Text: Die Textstruktur wird in HTML (= Hypertext Markup Language) geschrieben und mittels CCS (= Cascading Style Sheets) formatiert."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CujjG4fGofXy"
      },
      "source": [
        "# Woraus Webseiten gemacht sind: HTML\n",
        "\n",
        "\n",
        "<b>HTML (Hypertext Markup Language)</b> <br /> \n",
        "<li>Textbasierte Auszeichnungssprache zur Strukturierung elektronischer Dokumente wie Texte mit Hyperlinks oder Bildern</li> \n",
        "<li>Basiert auf XML</li> \n",
        "<li>Nutzt < tags > für die Strukturierung</li>\n",
        "<li>Zur besseren Übersichtlichkeit werden HTML-Tags eingerückt</li><br /> \n",
        "\n",
        "Beispiel HTML:\n",
        "```\n",
        "<html>\n",
        "    <body>\n",
        "        <h1>Star Wars Intro</h1>\n",
        "        <p>A long time ago in a galaxy far, far away....</p>\n",
        "...\n",
        "```\n",
        "\n",
        "Beachten Sie bitte, dass HTML-Tags in der Regel erst mit einem öffnenden < tag > und einen schließenden < /tag > komplett sind. Davon gibt es nur wenige Ausnahmen, wie bspw. den Tag < br >, der einen Zeilenumbruch beschreibt.\n",
        "\n",
        "Manche Tags haben auch noch zusätzliche Attribute, die dem Tag übergeben werden müssen. So braucht bspw. der Img-Tag (Tag zum einfügen eines Bildes) den Pfad zur Bilddatei (src = source), die aufgerufen werden soll.\n",
        "\n",
        "Beispiel:\n",
        "```\n",
        "<img src=\"files/picture.png\">\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J9st0d_dsOly"
      },
      "source": [
        "# Zeit für eine Übung!\n",
        "\n",
        "Probieren Sie es aus! Kopieren Sie sich den folgenden Code in einen Editor auf Ihrem Rechner. Als Windows-Nuter können Sie z.B. den ganz schlichten \"Editor\" von Windows benutzen. Auf dem Mac müssen Sie zunächst einen Editor installieren (Für diese Demo habe ich die Open Source-Software Brackets benutzt).\n",
        "\n",
        "```\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>\n",
        "            <img src=\"yoda.png\">\n",
        "        </td>\n",
        "\t      <td>\n",
        "            <h1>Yoda</h1>\n",
        "            <p><b>Yoda</b> (* 896 VSY; † 4 NSY auf Dagobah) gehörte einer unbekannten Spezies an, war 66 cm groß und war am Ende seines Lebens 900 Jahre alt. Er hatte in über 800 Jahren als <b>Jedi-(Groß-)Meister</b> zahlreiche Schüler in der Macht ausgebildet, darunter u. a. Luke Skywalker und Count Dooku, und war ein Meister im Umgang mit dem Lichtschwert. \n",
        "            </p>\n",
        "            <a href=\"https://de.wikipedia.org/wiki/Figuren_aus_Star_Wars#Yoda\">Link zur Wikipedia-Seite</a>\n",
        "\t      </td>\n",
        "     </tr>\n",
        "</table>\n",
        "```\n",
        "\n",
        "Bearbeiten Sie bitte die folgenden Aufgaben:\n",
        "*   Speichern Sie den Code ab und zwar mit der Dateiendung \".html\" (Achtung, vergewissern Sie sich, dass Sie nicht aus Versehen eine doppelte Dateiendung \".html.txt\" vergeben wen Sie mit dem Windows-Editor arbeiten). Doppelklicken Sie auf die Datei, um Sie sich im Browser anzusehen.\n",
        "*   Googeln Sie die Tags, die Sie noch nicht kennen. Was bedeuten sie?\n",
        "*   Versuchen Sie die Textstellen, die in \"fett\" formatiert sind, zusätzlich auch kursiv zu formatieren (ggf. googeln).  \n",
        "*   Passen Sie den Text so an, dass er eine Selbstbeschreibung Ihrer Person enthält. \n",
        "*   Warum lädt das Bild nicht? Können Sie das ändern?\n",
        "\n",
        "Wenn Sie die Datei mit einem Doppelklick öffnen, wird sie im Browser angezeigt. Dort können Sie sie nicht mehr editieren. Zum Editieren müssen Sie es wieder im Editor öffnen (Rechtsklick und \"Öffnen mit...\").\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WwehqfIKbGNm"
      },
      "source": [
        "# Cascading Style Sheets\n",
        "\n",
        "Die Website, die Sie in der vorigen Übung angelegt haben, funktioniert. Aber sie sieht wahrscheinlich nicht besonders schön aus.\n",
        "\n",
        "HTML beschreibt vorrangig die Struktur eines Textes. Standardmäßig sind auch Layouts für die unterschiedlichen Elemente festgelegt, so dass alle Browser ein reines HTML-Dokument in etwa gleich darstellen. Die Schrift ist z.B. Times oder eine andere Serifenschrift und eine Überschrift (H1) wird größer dargestellt als der Text (p). \n",
        "\n",
        "Um eine HTML-Datei jedoch zu layouten wird auf CSS (= Cascading Style Sheets) zurückgegriffen. CSS ist eine zusätzliche Sprache, die sich nur damit beschäftigt, wie Text oder andere Inhalte formatiert werden sollen. \n",
        "\n",
        "Man kann in CSS auch Klassen festlegen. Der Vorteil ist: Wenn etwas am Layout geändert werden soll, muss dies nur an einer Stelle in der .css-Datei geändert werden. - So ähnlich wie bei einer Formatvorlage in MS-Word.\n",
        "\n",
        "Beispiel CSS-Klasse \"error\" innerhalb des HTML-p-Tags:\n",
        "```\n",
        "p.error {\n",
        "  font-family: courier;\n",
        "  color: red;\n",
        "  font-size: 160%;\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qiB54dWsdv3P"
      },
      "source": [
        "# Komplexere HTML-Seiten\n",
        "Das obrige Beispiel einer Website ist zum Einstieg bewusst einfach gehalten. Es ist auch gar nicht das Ziel dieses Kurses, dass Sie HTML und CCS lernen und hinterher fließend coden können. Sie sollen lediglich grob verstehen, wie HTML und CCS aufgebaut sind. Denn das kann man nutzen, wenn man eine Webseite scrapen will.\n",
        "\n",
        "Schauen wir uns zunächst eine etwas komplexere Website an, bspw. https://www.europarl.europa.eu/meps/en/full-list. \n",
        "\n",
        "Auf dieser Seite werden die Abgeordneten des EU-Parlaments der aktuellen Wahlperiode aufgeführt. Wenn wir diese Seite scrapen, könnten wir eine Liste aller Abgeordneten mit ihrer Partei, ihrem Land und weiteren Informationen erstellen. Genau das wollen wir im Folgenden tun. Im ersten Schritt scrapen wir die Namen der Abgeordneten von der Seite.\n",
        "\n",
        "Doch zunächst schauen wir uns dazu das HTML der Seite an.\n",
        "\n",
        "Dazu klicken Sie im Browser mit Rechts auf die Seite und wählen \"Seitenquelltext anzeigen\" (oder ähnlich, je nach Browser). Im Browser öffnet sich ein neuer Tab, der den gesammten HTML-Code anzeigt.\n",
        "\n",
        "Die erste Abgeordnete heisst \"Magdalena ADAMOWICZ\" suchen Sie nach ihr! Sie müssten einen ähnlichen Quelltextausschnitt finden wie ich:\n",
        "\n",
        "![Bild vom Quellcode](http://julia-niemann.de/quellcode.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D8UYfyi_e2Zl"
      },
      "source": [
        "Man kann hier sehen, dass unterschiedliche Klassen verwendet werden, um den Text zu formatieren. Vor dem Namen (in gelb gehighlighted), wird bspw. die Klasse \"erpl_title-h5\" aufgerufen. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-dXHVDiMi02n"
      },
      "source": [
        "# Warum ist es wichtig die CSS-Klasse zu kennen?\n",
        "\n",
        "Eine berechtigte Frage, schließlich wollen wir ja keine Website formatieren und uns das Design abschauen (so schön ist das Layout der EU-Parlaments-Site auch nicht...). Es ist wichtig, weil wir über die Formatierung die <b>Inhalte identifizieren, die wir scrapen</b> wollen. Alle Abgeordneten Namen sind gleich formatiert. Wir müssen also aus dem HTML-Dokument nur die Tags herausziehen, die mit der von uns identifizierten Klasse \"erpl_title-h5\" formatiert wurden!\n",
        "\n",
        "Genau das macht das folgende R-Script. Es ist an dieser Stelle **nicht wichtig, dass Sie das Script im Detail verstehen**. Es geht hier nur darum zu demonstrieren was möglich ist. Der Output des Codes wird direkt darunter angezeigt.\n",
        "\n",
        "Beachten Sie, dass in Zeile 12 die von uns identifizierte CSS-Klasse eingefügt wurde.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lY6FTG0i5FdL",
        "colab": {}
      },
      "source": [
        "# load libraries\n",
        "library(rvest)\n",
        "library(tidyverse)\n",
        "\n",
        "# Store the URL you want to scrape as a new object \n",
        "# This is only the first page. To scrape all parlamentarians replace with: \n",
        "# https://www.europarl.europa.eu/meps/en/full-list/all\n",
        "eu_url <- \"https://www.europarl.europa.eu/meps/en/full-list\" \n",
        "\n",
        "# Download HTML code from that URL and save it in a new object\n",
        "eu_html <- read_html(eu_url, encoding = \"UTF-8\")\n",
        "\n",
        "eu_names <- html_nodes(eu_html,\".erpl_title-h5\") %>%\n",
        "            html_text()\n",
        "\n",
        "#Viewing list of names:\n",
        "eu_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MO4kUTkVXbDb"
      },
      "source": [
        "# Selector Gadget: Ein einfacherer Weg die Klasse herauszufinden\n",
        "\n",
        "Um nur die Klasse eine bestimmten Elements herauszufinden, muss man sich zum Glück nicht durch HTML-Wüsten wühlen. Es gibt dafür ein einfaches Tool, nämlich eine Browsererweiterung in Google Chrome: \"Selector Gadget\".\n",
        "\n",
        "Tutorial z.B. unter: https://www.youtube.com/watch?v=oqNTfWrGdbk\n",
        "\n",
        "Der Vorteil von Selector Gadget ist, dass man grafisch sehen kann, welche Inhalte auf einer Website mit einer CCS-Klasse formatiert wurden. Mann kann Inhalte anwählen und abwählen und das Selectorgadget gibt eine Kombination aus HTML-Tags und CCS-Classes zurück, die den interessierenden Inhalt eindeutig identfizieren.\n",
        "\n",
        "Für das obrige Beispiel gibt das Selector Gadget den folgenden Code zurück: \n",
        "\"#docMembersList .t-item\". Das ist nicht das gleiche wie \".erpl_title-h5\", liefert beim scraping aber ein ähnliches Ergebnis. Tatsächlich ist das Ergebnis sogar besser, weil der letzte Eintrag nicht \"Share this page\" lautet, sondern nur die Namen zurück gegeben werden:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RDtNL-MiyQ7Z",
        "colab": {}
      },
      "source": [
        "eu_names <- html_nodes(eu_html,\"#docMembersList .t-item\") %>%\n",
        "            html_text()\n",
        "\n",
        "#Viewing list of names:\n",
        "eu_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yDkoC0awyxHX"
      },
      "source": [
        "Genauso können auch die Länder der Parlamentarier von der Seite gescrapt werden. Wir müssen dazu nur den richtigen \"Identifier\" aus Tags und classes mit dem Selector Gadget herausfinden und in den Code einsetzen:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r71uMUGNXUcZ",
        "colab": {}
      },
      "source": [
        "#Fill in your code (you can copy the code from above and simply change the specific elements)\n",
        "eu_countries <- html_nodes(eu_html,\".mb-25+ .mb-25\") %>%\n",
        "                html_text()\n",
        "\n",
        "# We can now combine the two variables together and have a nice little dataset:\n",
        "data <- cbind(eu_names, eu_countries)\n",
        "head(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxuKaUsUMzyJ",
        "colab_type": "text"
      },
      "source": [
        "# Zeit für eine Übung!\n",
        "\n",
        "Versuchen Sie mal über den Quellcode oder mit dem Selector Gadget herauszufinden, wie die CSS-Klasse bzw. der Identifier für die Fraktion eines Parlamentariers lautet.\n",
        "\n",
        "Also z.B. bei Magdalena ADAMOWICZ:\n",
        "\"Group of the European People's Party (Christian Democrats)\"\n",
        "\n",
        "Was fällt ihnen auf?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uegV-LznZUxg"
      },
      "source": [
        "# Crawling\n",
        "\n",
        "Beim Crawling scraped man sich von einer Seite auf die nächste und versucht über verschiedene Einzelseiten (oder Webseiten) hinweg relevante Inhalte zu extrahieren. Das können wir selbstverständlich auch machen. Wir können bspw. von den Unterseiten der einzelnen Abgeordneten ihr Geburtsdatum extrahieren. Dazu brauchen wir aber zunächst eine Liste mit den Links von den einzelnen Abgeordneten-Seiten:  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xiaIXheL9BFM",
        "colab": {}
      },
      "source": [
        "# We nee a slightly different node this time:\n",
        "eu_links <- html_nodes(eu_html,\"#docMembersList div a\") %>%\n",
        "            html_attr(\"href\") \n",
        "\n",
        "# View the list of links:\n",
        "head(eu_links)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oDX6_NV5t31H"
      },
      "source": [
        "Die Links können nun nacheinander besucht werden um von den einzelnen Unterseiten auch die Geburtsdaten der Parlamentarier*innen zu scrapen:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YlMbXicn-RGu",
        "colab": {}
      },
      "source": [
        "# Before we start our for loop, we have to create an empty container object. \n",
        "# This empty container can be filled with specific content (in our case the dates of birth) through our for loop.\n",
        "eu_birthdates <- as.character()\n",
        "\n",
        "# In our for loop, we must define how often the element i of the link list is passed through. \n",
        "for (i in 1:length(eu_links)){\n",
        "\n",
        "  # Download html of current eu parlamentarian subpage\n",
        "  html_i <- read_html(eu_links[i], encoding = \"UTF-8\")\n",
        "\n",
        "  # Find the birth date node (inspector gadget)\n",
        "  birth_node_i <- html_nodes(html_i, \"#birthDate\")\n",
        "\n",
        "  # Now we extract the text of our specific node\n",
        "  birth_i <- html_text(birth_node_i)\n",
        "\n",
        "  # Not every parlamentarian has a birth date on their website. Therefore we need to check\n",
        "  if (length(birth_i) == 0) {\n",
        "    birth_i <- NA\n",
        "  }\n",
        "\n",
        "  # We append the new birth date to our previously empty container object\n",
        "  eu_birthdates <- append(eu_birthdates, birth_i)\n",
        "}\n",
        "\n",
        "# We now have a list of names and a list of birth dates. \n",
        "# Let´s bind them to our data set\n",
        "data <- cbind(data, eu_birthdates)\n",
        "\n",
        "# Outputting content to our console\n",
        "head(data)\n",
        "\n",
        "# Within a for loop you can include multiple nodes from which you want to extract content. \n",
        "# For each content you want to scrape, you only need to create an empty container variable first, which is then filled in the for loop. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zEeJ62EeRYWF"
      },
      "source": [
        "# Ausblick\n",
        "\n",
        "**Scraping bleibt eine wichtige Technik, gerade in der Post-API-Ära**\n",
        "*   Einzusetzen, wenn keine API zur Verfügung steht\n",
        "*   Besonders hilfreich wenn die Webseite immer gleich strukturierte Inhalte enthält \n",
        "*   Datenbereinigung ist der halbe Aufwand (wenn nicht mehr)!\n",
        "\n",
        "<br />\n",
        "\n",
        "**Ethische und rechtliche Aspekte**\n",
        "\n",
        "*   Ethische Grundsätze beachten, verantwortungsvoll Handeln (Privatsphäre!)\n",
        "*   Legalität: Vor dem Scrapen die Terms & Conditions der Website checken.\n",
        "*   Rechtliche Lage im Wissenschaftsbereich unklar (EU-Richtlinie).\n",
        "*   Keine Inhalte hiner einem Log-In oder einer Paywall scrapen (auch wenn das technisch kein Problem wäre).\n",
        "*   Achtung, auch Scraping ist Traffic auf der Seite.\n",
        "\n",
        "<br />\n",
        "\n",
        "**Advanced Scraping**\n",
        "\n",
        "Scraping bietet viele weitere Möglichkeiten, wenn die Webseiten komplexer werden. Bspw:\n",
        "*   Webformulare ausfüllen und senden\n",
        "*   Download von Bildern/Videos\n",
        "*   Auswahl der Inhalte über X-Path \n",
        "*   Dynamische Webseiten (javascript)\n",
        "*   ...\n",
        "\n",
        "<br />\n",
        "\n",
        "**Weiterführende Literatur**\n",
        "\n",
        "Munzert, S., Ruoba, C., Meiboner, P., & Nyhuis, D. (2015). *Automated Data Collection with R: A practical Guide to Web Scraping and Text Mining.* Chichester, United Kingdom: John Wiley & Sons. \n"
      ]
    }
  ]
}